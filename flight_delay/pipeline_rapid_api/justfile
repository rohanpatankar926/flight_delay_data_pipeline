image_name := 'spark_pipeline:v1'
aws_access_key_id := ''
aws_secret_access_key := ''


build: 
    docker build -t {{image_name}} .

run: 
    sudo docker run  --mount type=bind,source="$(pwd)",target=/opt/application/   -e AWS_ACCESS_KEY_ID={{aws_access_key_id}}   -e AWS_SECRET_ACCESS_KEY={{aws_secret_access_key}}   pipeline_spark:v1   spark-submit --master local   /opt/application/data_pipeline.py